{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ok-ffb1-hmK"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENvU8XdO-sBt",
        "outputId": "428470fe-3e51-4f22-f305-02e181e6b7a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.203770\n",
            "Epoch 2/10, Loss: 0.188315\n",
            "Epoch 3/10, Loss: 0.173950\n",
            "Epoch 4/10, Loss: 0.160530\n",
            "Epoch 5/10, Loss: 0.147930\n",
            "Epoch 6/10, Loss: 0.136068\n",
            "Epoch 7/10, Loss: 0.124906\n",
            "Epoch 8/10, Loss: 0.114437\n",
            "Epoch 9/10, Loss: 0.104697\n",
            "Epoch 10/10, Loss: 0.095769\n",
            "Model saved as lstm_stock_model.pth\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Fetch stock data\n",
        "data = yf.download(\"GOOG\", start=\"2012-01-01\", end=\"2024-01-01\")  # Change the ticker if needed\n",
        "close_prices = data['Close'].values.reshape(-1, 1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(close_prices)\n",
        "\n",
        "# Prepare training data (using past 30 days to predict next day)\n",
        "X_train, y_train = [], []\n",
        "for i in range(30, len(scaled_data)):\n",
        "    X_train.append(scaled_data[i-30:i, 0])\n",
        "    y_train.append(scaled_data[i, 0])\n",
        "\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "# Define LSTM model\n",
        "class LSTMStockPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMStockPredictor, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=2, batch_first=True)\n",
        "        self.fc = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.fc(x[:, -1, :])  # Take last output\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "model = LSTMStockPredictor()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs.squeeze(), y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), \"lstm_stock_model.pth\")\n",
        "\n",
        "# Save the scaler for later use\n",
        "import joblib\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "\n",
        "print(\"Model saved as lstm_stock_model.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI_O6AJ1WvH3"
      },
      "source": [
        "# XGBOOST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFJszXdaW_Jg"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare the data\n",
        "X, y = [], []\n",
        "for i in range(60, len(scaled_data)):\n",
        "    X.append(scaled_data[i-60:i, 0])\n",
        "    y.append(scaled_data[i, 0])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Split into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.01)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Forecast next 7 days\n",
        "future_X = X[-1:]\n",
        "xgb_predictions = []\n",
        "for _ in range(7):\n",
        "    pred = xgb_model.predict(future_X)\n",
        "    xgb_predictions.append(pred[0])\n",
        "    future_X = np.append(future_X[:, 1:], pred).reshape(1, 60)\n",
        "\n",
        "# Rescale predictions\n",
        "xgb_predictions = scaler.inverse_transform(np.array(xgb_predictions).reshape(-1, 1)).flatten()\n",
        "\n",
        "# Display predictions\n",
        "print(\"XGBoost Predictions for Next 7 Days:\", xgb_predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfugttdtXA1i"
      },
      "source": [
        "# LIGHTGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sStsVBaYXC5V"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# Step 1: Fetch the latest stock data\n",
        "today = datetime.now().strftime('%Y-%m-%d')\n",
        "data = yf.download('GOOG', start='2012-01-01', end=today)\n",
        "\n",
        "# Step 2: Prepare the data\n",
        "close_prices = data['Close']\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(close_prices.values.reshape(-1, 1))\n",
        "\n",
        "# Step 3: Prepare training and testing datasets\n",
        "X, y = [], []\n",
        "for i in range(60, len(scaled_data)):\n",
        "    X.append(scaled_data[i-60:i, 0])\n",
        "    y.append(scaled_data[i, 0])\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Train LightGBM model\n",
        "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
        "lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
        "\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.01,\n",
        "    'feature_fraction': 0.9,\n",
        "    'early_stopping_round': 50  # Early stopping rounds in the params dictionary\n",
        "}\n",
        "\n",
        "lgb_model = lgb.train(params, lgb_train, valid_sets=[lgb_test], num_boost_round=1000)\n",
        "\n",
        "# Step 5: Forecast the next 7 days\n",
        "X_last_60 = scaled_data[-60:].reshape(1, -1)\n",
        "lgb_predictions = []\n",
        "for _ in range(7):\n",
        "    pred = lgb_model.predict(X_last_60)\n",
        "    lgb_predictions.append(pred[0])\n",
        "    X_last_60 = np.append(X_last_60[0][1:], pred).reshape(1, -1)\n",
        "\n",
        "# Rescale predictions back to original prices\n",
        "lgb_predictions = scaler.inverse_transform(np.array(lgb_predictions).reshape(-1, 1)).flatten()\n",
        "\n",
        "# Step 6: Plot the results\n",
        "future_dates = pd.date_range(datetime.now().date(), periods=7, freq='B')\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(close_prices[-200:], label=\"Actual\")\n",
        "plt.plot(future_dates, lgb_predictions, label=\"LGBM Predictions\", linestyle='--')\n",
        "plt.title('GOOGLE Stock Price Prediction for Next 7 Days (LightGBM)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price (USD)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Display predictions\n",
        "print(f\"LGBM Predictions for Next 7 Days: {lgb_predictions}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ1c4ud1XEH2"
      },
      "source": [
        "# GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy0WlR2gXFmr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import yfinance as yf\n",
        "\n",
        "# Step 1: Fetch Google stock price data up to today\n",
        "data = yf.download('GOOG', start='2012-01-01', end=pd.Timestamp.today().strftime('%Y-%m-%d'))\n",
        "data = data[['Close']]  # Use only the closing price\n",
        "data.index = pd.to_datetime(data.index)\n",
        "\n",
        "# Step 2: Scale data for GRU model\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data['Close'].values.reshape(-1, 1))\n",
        "\n",
        "# Prepare training data\n",
        "seq_length = 60  # Use the last 60 days to predict the next day\n",
        "X, y = [], []\n",
        "for i in range(seq_length, len(scaled_data)):\n",
        "    X.append(scaled_data[i-seq_length:i])\n",
        "    y.append(scaled_data[i])\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Step 3: Build and train the GRU model\n",
        "model = Sequential([\n",
        "    GRU(50, return_sequences=True, input_shape=(seq_length, 1)),\n",
        "    GRU(50),\n",
        "    Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X, y, epochs=20, batch_size=32, verbose=1)\n",
        "\n",
        "# Step 4: Forecast the next 7 days\n",
        "last_sequence = scaled_data[-seq_length:]  # Last 60 days as input\n",
        "last_sequence = last_sequence.reshape(1, seq_length, 1)  # Reshape for model input\n",
        "\n",
        "future_prices = []\n",
        "for _ in range(7):\n",
        "    next_price = model.predict(last_sequence)[0, 0]  # Predict next price\n",
        "    future_prices.append(next_price)\n",
        "    next_sequence = np.append(last_sequence[0, 1:], [[next_price]], axis=0)\n",
        "    last_sequence = next_sequence.reshape(1, seq_length, 1)\n",
        "\n",
        "# Convert scaled predictions back to original prices\n",
        "future_prices_actual = scaler.inverse_transform(np.array(future_prices).reshape(-1, 1))\n",
        "\n",
        "# Step 5: Create future dates\n",
        "future_dates = pd.date_range(start=pd.Timestamp.today(), periods=8)[1:]  # Next 7 days\n",
        "forecast_df = pd.DataFrame({'Date': future_dates, 'Forecasted Price': future_prices_actual.flatten()})\n",
        "\n",
        "# Step 6: Visualization\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(data.index[-100:], data['Close'].values[-100:], label=\"Historical Prices\")\n",
        "plt.plot(forecast_df['Date'], forecast_df['Forecasted Price'], label=\"Forecasted Prices\", marker='o')\n",
        "plt.title(\"Google Stock Price Forecast for the Next 7 Days\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print forecasted prices\n",
        "print(\"Forecasted Prices for the Next 7 Days:\")\n",
        "print(forecast_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDEwzwRyXGzZ"
      },
      "source": [
        "# SARIMAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfbE4Q24XIRm"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Fit SARIMAX model\n",
        "model = SARIMAX(close_prices, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
        "results = model.fit()\n",
        "\n",
        "# Forecast the next 7 days\n",
        "forecast = results.get_forecast(steps=7)\n",
        "forecast_df = forecast.summary_frame()\n",
        "\n",
        "# Display predictions\n",
        "print(forecast_df[['mean', 'mean_ci_lower', 'mean_ci_upper']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ci782DwXKFA"
      },
      "source": [
        "Discord Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gQrrnLm6XV70",
        "outputId": "0c18b191-cef5-42df-973f-c895ede3b52c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: discord in /usr/local/lib/python3.11/dist-packages (2.3.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.52)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: discord.py>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from discord) (2.4.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: aiohttp<4,>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from discord.py>=2.3.2->discord) (3.11.12)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (1.17.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.3.2->discord) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.3.2->discord) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.3.2->discord) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.3.2->discord) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.3.2->discord) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.3.2->discord) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.3.2->discord) (1.18.3)\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"2syEU0lluGcpWCczw8FxLEcr69i_5Qc7TjGYU5tcjguPDUbNH\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dDmV6L1Okkgk",
        "outputId": "c011baf1-3f46-4d05-8ded-00dba20edaa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: discord.py in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.52)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from discord.py) (3.11.12)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4,>=3.7.4->discord.py) (1.18.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install discord.py nest-asyncio yfinance numpy pandas tensorflow scikit-learn xgboost\n",
        "import discord\n",
        "import nest_asyncio\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from discord.ext import commands\n",
        "\n",
        "# Required for Google Colab to run async functions\n",
        "nest_asyncio.apply()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lq6dyYqXK9f",
        "outputId": "3eb4d760-e336-410a-e592-87146a6961dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:39\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "INFO:discord.client:logging in using static token\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "\u001b[30;1m2025-02-13 05:29:40\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n",
            "INFO:discord.gateway:Shard ID None has connected to Gateway (Session ID: bd9b9dcd49398979264e9c23dece16d1).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Logged in as Compare AI#0380\n",
            "📌 Command received: !predict TSLA\n",
            "📊 Predicting for TSLA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
            "  self._init_dates(dates, freq)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000425 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2220\n",
            "[LightGBM] [Info] Number of data points in the train set: 219, number of used features: 30\n",
            "[LightGBM] [Info] Start training from score 0.348537\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
            "  return get_prediction_index(\n",
            "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
            "  return get_prediction_index(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-c6cf840a0f5e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_bot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 scheduled[0]._when - self.time(), 0), 86400) if scheduled\n\u001b[1;32m    114\u001b[0m             else None)\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mevent_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import discord\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from discord.ext import commands\n",
        "\n",
        "# Allow async in Google Colab\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Discord Bot Setup\n",
        "TOKEN = \"MTMzOTQxMjk4Nzc1NjI4NjA1NQ.GMeU50.qenW_KcCND_XeT0dwr1wAJ-n6MUDyDh8x4GtaU\"\n",
        "intents = discord.Intents.default()\n",
        "intents.messages = True\n",
        "intents.message_content = True\n",
        "bot = commands.Bot(command_prefix=\"!\", intents=intents)\n",
        "\n",
        "@bot.event\n",
        "async def on_ready():\n",
        "    print(f\"✅ Logged in as {bot.user}\")\n",
        "\n",
        "@bot.command()\n",
        "async def hello(ctx):\n",
        "    await ctx.send(\"Hello!\")\n",
        "\n",
        "# Function to fetch stock data\n",
        "def fetch_stock_data(ticker):\n",
        "    stock = yf.Ticker(ticker)\n",
        "    df = stock.history(period=\"1y\")  # Get past year data\n",
        "    return df if not df.empty else None\n",
        "\n",
        "# Preprocess data\n",
        "def preprocess_data(data):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(data[['Close']])\n",
        "    return scaled_data, scaler\n",
        "\n",
        "# Prepare sequences (Fix: Predict only next day's price)\n",
        "def prepare_sequences(data, seq_length=30):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length - 1):  # Predict only the next day\n",
        "        X.append(data[i:i+seq_length])\n",
        "        y.append(data[i+seq_length])  # Single value target\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Build LSTM Model\n",
        "def build_lstm_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(50, activation='relu', return_sequences=True, input_shape=input_shape),\n",
        "        LSTM(50, activation='relu'),\n",
        "        Dense(1)  # Predict 1 day\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# Build GRU Model\n",
        "def build_gru_model(input_shape):\n",
        "    model = Sequential([\n",
        "        GRU(50, activation='relu', return_sequences=True, input_shape=input_shape),\n",
        "        GRU(50, activation='relu'),\n",
        "        Dense(1)  # Predict 1 day\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# Train LSTM/GRU model\n",
        "def train_model(model, X_train, y_train):\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
        "    return model\n",
        "\n",
        "# Train XGBoost (Fix: Ensure correct target shape)\n",
        "def train_xgboost(X_train, y_train):\n",
        "    model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100)\n",
        "    model.fit(X_train.reshape(X_train.shape[0], -1), y_train.ravel())  # Ensure correct shape\n",
        "    return model\n",
        "\n",
        "# Train LightGBM (Fix: Ensure correct target shape)\n",
        "def train_lightgbm(X_train, y_train):\n",
        "    model = lgb.LGBMRegressor(n_estimators=100)\n",
        "    model.fit(X_train.reshape(X_train.shape[0], -1), y_train.ravel())  # Ensure correct shape\n",
        "    return model\n",
        "\n",
        "# Train SARIMAX\n",
        "def train_sarimax(data):\n",
        "    model = SARIMAX(data, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "    result = model.fit(disp=False)\n",
        "    return result\n",
        "\n",
        "# Predict stock prices\n",
        "def predict_stock(ticker):\n",
        "    print(f\"📊 Predicting for {ticker}...\")\n",
        "\n",
        "    # Fetch data\n",
        "    data = fetch_stock_data(ticker)\n",
        "    if data is None:\n",
        "        return f\"⚠️ No data found for {ticker}\"\n",
        "\n",
        "    # Preprocess\n",
        "    data_scaled, scaler = preprocess_data(data)\n",
        "    X, y = prepare_sequences(data_scaled)\n",
        "    X_train, y_train = X[:-1], y[:-1]  # Use all but the last for training\n",
        "    X_test = X[-1].reshape(1, *X.shape[1:])  # Use the last sequence for prediction\n",
        "\n",
        "    # Train models\n",
        "    lstm_model = train_model(build_lstm_model((30,1)), X_train, y_train)\n",
        "    gru_model = train_model(build_gru_model((30,1)), X_train, y_train)\n",
        "    xgb_model = train_xgboost(X_train, y_train)\n",
        "    lgb_model = train_lightgbm(X_train, y_train)\n",
        "    sarimax_model = train_sarimax(data['Close'])\n",
        "\n",
        "    # Predictions (Fix: Reshape correctly)\n",
        "    predictions = {\n",
        "        'LSTM': scaler.inverse_transform(lstm_model.predict(X_test).reshape(-1,1))[0],\n",
        "        'GRU': scaler.inverse_transform(gru_model.predict(X_test).reshape(-1,1))[0],\n",
        "        'XGBoost': scaler.inverse_transform(xgb_model.predict(X_test.reshape(1,-1)).reshape(-1,1))[0],\n",
        "        'LightGBM': scaler.inverse_transform(lgb_model.predict(X_test.reshape(1,-1)).reshape(-1,1))[0],\n",
        "        'SARIMAX': scaler.inverse_transform(sarimax_model.forecast(steps=1).values.reshape(-1,1))[0],\n",
        "    }\n",
        "\n",
        "    # Format results\n",
        "    result = f\"📈 **Predictions for {ticker}** for the next 7 days\\n\"\n",
        "    result += f\"Current Price: **{data['Close'].iloc[-1]:.2f}**\\n\"\n",
        "    for model, pred in predictions.items():\n",
        "        result += f\"**{model}**: {pred[0]:.2f}\\n\"\n",
        "\n",
        "    return result\n",
        "\n",
        "# Discord command\n",
        "@bot.command()\n",
        "async def predict(ctx, ticker: str):\n",
        "    try:\n",
        "        print(f\"📌 Command received: !predict {ticker}\")\n",
        "        result = predict_stock(ticker.upper())\n",
        "        await ctx.send(result)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error: {e}\")\n",
        "        await ctx.send(f\"Error: {e}\")\n",
        "\n",
        "# Run the bot\n",
        "async def run_bot():\n",
        "    async with bot:\n",
        "        await bot.start(TOKEN)\n",
        "\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(run_bot())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}